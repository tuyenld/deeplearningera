<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://deeplearningera.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://deeplearningera.com/" rel="alternate" type="text/html" /><updated>2021-05-17T01:13:25+00:00</updated><id>https://deeplearningera.com/feed.xml</id><title type="html">deeplearningera.com</title><subtitle>A blog from Dinh-Tuyen Le, an independent developer who's passionate about clean, testable code.</subtitle><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><entry><title type="html">OpenCV C++ getting started</title><link href="https://deeplearningera.com/opencv-getting-started/" rel="alternate" type="text/html" title="OpenCV C++ getting started" /><published>2021-03-25T00:00:00+00:00</published><updated>2021-03-25T00:00:00+00:00</updated><id>https://deeplearningera.com/opencv</id><content type="html" xml:base="https://deeplearningera.com/opencv-getting-started/">&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;h3 id=&quot;download&quot;&gt;Download&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Microsoft Visual C++ 2019 &lt;a href=&quot;https://download.visualstudio.microsoft.com/download/pr/3a7354bc-d2e4-430f-92d0-9abd031b5ee5/d9fc228ea71a98adc7bc5f5d8e8800684c647e955601ed721fcb29f74ace7536/vs_Community.exe&quot;&gt;Community&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nchc.dl.sourceforge.net/project/opencvlibrary/4.5.1/opencv-4.5.1-vc14_vc15.exe&quot;&gt;opencv_4.5.1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nchc.dl.sourceforge.net/project/opencvlibrary/3.4.13/opencv-3.4.13-vc14_vc15.exe&quot;&gt;opencv_3.4.13&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;configure&quot;&gt;Configure&lt;/h3&gt;
&lt;p&gt;https://acodary.wordpress.com/2018/07/24/opencv-cai-dat-opencv-visual-c-tren-windows/&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Project &amp;gt; Property
    &lt;ul&gt;
      &lt;li&gt;Platform: x64&lt;/li&gt;
      &lt;li&gt;Configuration Properties
        &lt;ul&gt;
          &lt;li&gt;C/C++ &amp;gt; General: opencv\build\include&lt;/li&gt;
          &lt;li&gt;Linker &amp;gt; General: opencv\build\x64\vc15\lib&lt;/li&gt;
          &lt;li&gt;Linker &amp;gt; Input:
            &lt;ul&gt;
              &lt;li&gt;For openCV_4.5.1: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world451d.lib&lt;/code&gt; OR &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world451.lib&lt;/code&gt; (d for debug)&lt;/li&gt;
              &lt;li&gt;For opencv_3.4.13: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world3413d.lib&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;D:\tuyenld\dev\opencv_3.4.13\build\x64\vc15\bin&lt;/code&gt; (remember to correct your path) to PATH environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tăng-cường-chất-lượng-hình-ảnh&quot;&gt;Tăng cường chất lượng hình ảnh&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Phương pháp xử lý trên điểm ảnh
    &lt;ul&gt;
      &lt;li&gt;Biến đổi tuyến tính từng đoạn&lt;/li&gt;
      &lt;li&gt;Biến đổi Logarithm&lt;/li&gt;
      &lt;li&gt;Biến đổi âm bản&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Biến đổi tuyến tính từng đoạn
    &lt;ul&gt;
      &lt;li&gt;xử lý độ tương phản - giãn độ tương phản
        &lt;ul&gt;
          &lt;li&gt;xử lý những ảnh có độ tương phản thấp&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;cắt lớp cường độ sáng&lt;/li&gt;
      &lt;li&gt;tách nhiễu và lấy ngưỡng ảnh&lt;/li&gt;
      &lt;li&gt;cắt lớp bit&lt;/li&gt;
      &lt;li&gt;Biến đổi âm bản&lt;/li&gt;
      &lt;li&gt;Biến đổi dải động&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;histogram-equalization-he&quot;&gt;Histogram equalization (HE)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Đây chỉ là một phương pháp, có thể cho kết quả không phải flat toàn spectrum&lt;/li&gt;
  &lt;li&gt;Nếu histogram một bài toán thay đổi liên tục thì phải dùng HE (tự động). Các trường hợp khác thì có thể fixed histogram và không cần dùng đến HE00&lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;learning-opencv-3-computer-vision-in-c-with-the-opencv-library-adrian-kaehler-and-gary-bradski&quot;&gt;Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski)&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://github.com/oreillymedia/Learning-OpenCV-3_examples&lt;/p&gt;

&lt;h3 id=&quot;code&quot;&gt;Code&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.opencv.org/3.4.13&quot;&gt;Online&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;distancetransform&quot;&gt;distanceTransform&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm&quot;&gt;Ref1&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;takes &lt;strong&gt;binary images&lt;/strong&gt; as inputs.&lt;/li&gt;
  &lt;li&gt;the &lt;strong&gt;gray level intensities&lt;/strong&gt; of the points inside the foreground regions are changed to distance their respective distances from the closest 0 value (boundary)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;type&quot;&gt;Type&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ninghang.blogspot.com/2012/11/list-of-mat-type-in-opencv.html&quot;&gt;Ref1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/8377091/what-are-the-differences-between-cv-8u-and-cv-32f-and-what-should-i-worry-about/8377146&quot;&gt;Ref2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A Mapping of Type to Numbers in OpenCV&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;C1&lt;/th&gt;
      &lt;th&gt;C2&lt;/th&gt;
      &lt;th&gt;C3&lt;/th&gt;
      &lt;th&gt;C4&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Bits&lt;/th&gt;
      &lt;th&gt;C++ type&lt;/th&gt;
      &lt;th&gt;Range&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_8U&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;Unsigned&lt;/td&gt;
      &lt;td&gt;8bits&lt;/td&gt;
      &lt;td&gt;uchar&lt;/td&gt;
      &lt;td&gt;0~255&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_8S&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;8bits&lt;/td&gt;
      &lt;td&gt;char&lt;/td&gt;
      &lt;td&gt;-128~127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_16U&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;Unsigned&lt;/td&gt;
      &lt;td&gt;16bits&lt;/td&gt;
      &lt;td&gt;ushort&lt;/td&gt;
      &lt;td&gt;0~65.535&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_16S&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;16bits&lt;/td&gt;
      &lt;td&gt;short&lt;/td&gt;
      &lt;td&gt;-32.768~32.767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_32S&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;32bits&lt;/td&gt;
      &lt;td&gt;int&lt;/td&gt;
      &lt;td&gt;-2.147.483.648~2.147.483.647&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_32F&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;Float&lt;/td&gt;
      &lt;td&gt;32bits&lt;/td&gt;
      &lt;td&gt;float&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0~1.0&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_64F&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;Double&lt;/td&gt;
      &lt;td&gt;64bits&lt;/td&gt;
      &lt;td&gt;double&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#define CV_8U   0
#define CV_8S   1 
#define CV_16U  2
#define CV_16S  3
#define CV_32S  4
#define CV_32F  5
#define CV_64F  6
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define CV_8UC1 CV_MAKETYPE(CV_8U,1)
#define CV_8UC2 CV_MAKETYPE(CV_8U,2)
#define CV_8UC3 CV_MAKETYPE(CV_8U,3)
#define CV_8UC4 CV_MAKETYPE(CV_8U,4)
#define CV_8UC(n) CV_MAKETYPE(CV_8U,(n))
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define CV_CN_SHIFT   3
#define CV_DEPTH_MAX  (1 &amp;lt;&amp;lt; CV_CN_SHIFT)
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define CV_MAT_DEPTH_MASK       (CV_DEPTH_MAX - 1)
#define CV_MAT_DEPTH(flags)     ((flags) &amp;amp; CV_MAT_DEPTH_MASK)
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define CV_MAKETYPE(depth,cn) (CV_MAT_DEPTH(depth) + (((cn)-1) &amp;lt;&amp;lt; CV_CN_SHIFT))
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// For example: &lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define CV_8UC4 CV_MAKETYPE(CV_8U,4)
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// has type: 0+((4-1) &amp;lt;&amp;lt; 3) == 24&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;1 is the default number of channels (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CV_8U = CV_8UC1 = 0&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;CV_32F defines the depth of each element of the matrix&lt;/li&gt;
  &lt;li&gt;CV_32FC1 defines both the depth of each element and the number of channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scalar&quot;&gt;Scalar&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Template class for a 4-element vector derived from Vec.
Being derived from Vec&amp;lt;Tp, 4&amp;gt; , 
Scalar can be used just as typical 4-element vectors. 
The type Scalar is widely used in OpenCV to pass pixel values.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scalar&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Scala0: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;; Scala1: &quot;&lt;/span&gt; 
     &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;; Scala2: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Scala0: 255; Scala1: 255; Scala2: 500&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;differences-of-using-const-cvmat--cvmat--cvmat-or-const-cvmat-as-function-parameters&quot;&gt;Differences of using “const cv::Mat &amp;amp;”, “cv::Mat &amp;amp;”, “cv::Mat” or “const cv::Mat” as function parameters?&lt;/h3&gt;

&lt;p&gt;https://stackoverflow.com/a/23486280&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;OpenCV handles all the memory &lt;a href=&quot;https://docs.opencv.org/2.4/modules/core/doc/intro.html#automatic-memory-management&quot;&gt;automatically&lt;/a&gt;.
First of all, std::vector, Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the Mat::clone method that creates a full copy of the matrix data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;linear-vs-non-linear-filter&quot;&gt;Linear vs non-linear filter&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.embeddedcomputing.com/technology/analog-and-power/comparing-linear-versus-nonlinear-filters-in-image-processing&quot;&gt;Ref&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;In cases where the input data contains a large amount of noise but the magnitude is low, a linear low-pass filter may suffice.&lt;/li&gt;
    &lt;li&gt;Conversely, if an image contains a low amount of noise but with relatively high magnitude, then a median filter may be more appropriate. In either case, the filter process changes the overall frequency content of the image.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;but-what-is-the-fourier-transform-a-visual-introduction&quot;&gt;But what is the Fourier Transform? A visual introduction&lt;/h3&gt;

&lt;p&gt;https://youtu.be/spUNpyF58BY&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fourier Series &amp;gt; Periodic function of a continuous variable&lt;/li&gt;
  &lt;li&gt;Fourier Transform &amp;gt; Not periodic function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;clahe&quot;&gt;CLAHE&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20120113220509/http://radonc.ucsf.edu/research_group/jpouliot/tutorial/HU/Lesson7.htm&quot;&gt;Contrast Limited Adaptative Histogram Equalization (CLAHE)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/erich666/GraphicsGems/blob/master/gemsiv/clahe.c&quot;&gt;clahe.c&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cas.xav.free.fr/Graphics%20Gems%204%20-%20Paul%20S.%20Heckbert.pdf&quot;&gt;Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV p482/579&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Division of the image into 8x8 contextual regions usually gives good results; this implies 64 contextual regions of size 64x64 when AHE is performed on a 512x512 image&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;??&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To avoid visibility of region boundaries, a &lt;a href=&quot;https://theailearner.com/2018/12/29/image-processing-bilinear-interpolation/&quot;&gt;bilinear interpolation&lt;/a&gt; scheme is used (see Fig.2)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;laplacianlaplacian-of-gaussian&quot;&gt;Laplacian/Laplacian of Gaussian&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm&lt;/li&gt;
  &lt;li&gt;https://hcimage.com/help/Content/Quantitation/Measurements/Processing%20and%20Analysis/Enhance/Enhance%20Operations.htm&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://softwarebydefault.com/2013/05/11/image-edge-detection/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/Iz6C1ny-F2Q&quot;&gt;The Two-Dimensional Discrete Fourier Transform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/YYGltoYEmKo&quot;&gt;2-Dimensional Discrete-Space Fourier Transform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;edge preserving filter in image processing opencv&lt;/p&gt;

&lt;h3 id=&quot;wavelet&quot;&gt;Wavelet&lt;/h3&gt;

&lt;p&gt;http://www.nsl.hcmus.edu.vn/greenstone/collect/tiensifu/index/assoc/HASH01f6.dir/2.pdf
&lt;a href=&quot;https://blancosilva.wordpress.com/teaching/mathematical-imaging/denoising-wavelet-thresholding/&quot;&gt;Denoising: wavelet thresholding&lt;/a&gt;
&lt;a href=&quot;https://vdocuments.mx/download/ung-dung-phep-bien-doi-wavelet-trong-xu-ly-anh&quot;&gt;Ứng dụng phép biến đổi wavelet trong xử lý ảnh PTIT&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mean-vs-median-filter&quot;&gt;Mean vs Median filter&lt;/h3&gt;
&lt;p&gt;The “mean” is the “average” you’re used to, where you add up all the numbers and then divide by the number of numbers. 
The “median” is the “middle” value in the list of numbers.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Median filter: thích hợp cho ảnh grayscale, không dùng cho binary image&lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;point2f-sub-pixel-coordinate-origin&quot;&gt;Point2f, sub-pixel coordinate origin&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;References:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://answers.opencv.org/question/87923/sub-pixel-coordinate-origin/&quot;&gt;Sub-pixel coordinate origin&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/opencv/opencv/issues/10130&quot;&gt;Absent documentation for sub-pixel coordinate system&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;According to results above it seems that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cv2.remap&lt;/code&gt; uses coordinate system with pixel centers aligned to their integer indexes.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;top-left pixel center&lt;/code&gt; coordinate is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0,0)&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;top left pixel spans from (-0.5,-0.5) to (+0.5,+0.5)&lt;/li&gt;
      &lt;li&gt;whole image spans from (-0.5,-0.5) to (W-0.5, H-0.5)
&lt;img src=&quot;/images/point2f-coordinate.png&quot; alt=&quot;Point2f coordinate&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understanding-and-evaluating-template-matching-methods&quot;&gt;Understanding and evaluating template matching methods&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/a/58160295&quot;&gt;alkasm’s anwser&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TM_SQDIFF_NORMED, TM_CCORR_NORMED, TM_CCOEFF_NORMED
TM_SQDIFF, TM_CCORR, TM_CCOEFF&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;TM_CCOEFF_NORMED&lt;/th&gt;
      &lt;th&gt;TM_CCORR_NORMED&lt;/th&gt;
      &lt;th&gt;TM_SQDIFF_NORMED&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[-1, 1] (mean shifted)&lt;/td&gt;
      &lt;td&gt;[0, 1]&lt;/td&gt;
      &lt;td&gt;[0, 1]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;understanding-moments-function-in-opencv&quot;&gt;Understanding Moments function in opencv&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/a/22472044&quot;&gt;Michael Burdinov’s answer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Definition of moments in image processing is borrowed from physics. Assume that each pixel in image has weight that is equal to its intensity. Then the point you defined is centroid (a.k.a. center of mass) of image.&lt;/p&gt;

&lt;p&gt;Assume that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;I(x,y)&lt;/code&gt; is the intensity of pixel &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x,y)&lt;/code&gt; in image. Then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m(i,j)&lt;/code&gt; is the sum for all possible x and y of: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;I(x,y) * (x^i) * (y^j)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And &lt;a href=&quot;https://en.wikipedia.org/wiki/Image_moment&quot;&gt;here&lt;/a&gt; you can read a wiki article about all kinds of image moments (raw moments, central moments, scale/rotation invariant moments and so on). It is pretty good one and I recommend reading it.&lt;/p&gt;

&lt;p&gt;Adapting this to scalar (greyscale) image with pixel intensities I(x,y), raw image moments Mij are calculated by:
${\displaystyle M_{ij}=\sum &lt;em&gt;{x}\sum _{y}x^{i}y^{j}I(x,y)\,!}M&lt;/em&gt;=\sum _{x}\sum _{y}x^{i}y^{j}I(x,y)\,!$&lt;/p&gt;

&lt;p&gt;Centroid: ${\displaystyle \,\ {\bar {y}}}=\left{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}{\displaystyle \,\ {\bar {y}}}=\left{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}$&lt;/p&gt;

&lt;h2 id=&quot;clone-all-fiji-source-code&quot;&gt;Clone all Fiji source code&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# https://forum.image.sc/t/getting-the-source-code-for-fiji-without-using-maven/31964/6&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;maven
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;libxml2-utils

git clone git://github.com/fiji/fiji
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;fiji/bin
wget https://github.com/scijava/scijava-scripts/raw/master/melting-pot.sh
bin/melt.sh &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;findcontours&quot;&gt;findContours()&lt;/h2&gt;
&lt;p&gt;Reference:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://amroamroamro.github.io/mexopencv/opencv/contours_hierarchy_demo.html&quot;&gt;mexopencv&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a&quot;&gt;group__imgproc__shape&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In OpenCV, object to be found should be white and background should be black.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findContours&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;InputOutputArray&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;OutputArrayOfArrays&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contours&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;OutputArray&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;hierarchy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;                 &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;                 &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;               &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;// Note: absolute value of an area is used because&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// area may be positive or negative - in accordance with the&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// contour orientation&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fabs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contourArea&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contour1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Contour Approximation Method&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;CHAIN_APPROX_NONE vs CHAIN_APPROX_SIMPLE&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/findcontours-method.png&quot; alt=&quot;findcontours-method&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contours Hierarchy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/find-contours-hierarchy.png&quot; alt=&quot;find-contours-hierarchy&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Contour &lt;strong&gt;0,1,2&lt;/strong&gt; are the same hierachy level&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;child&lt;/em&gt;(2) = 2a; &lt;em&gt;parent&lt;/em&gt;(2a) = 2&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="opencv" /><summary type="html">Install Download Microsoft Visual C++ 2019 Community opencv_4.5.1 opencv_3.4.13 Configure https://acodary.wordpress.com/2018/07/24/opencv-cai-dat-opencv-visual-c-tren-windows/ Project &amp;gt; Property Platform: x64 Configuration Properties C/C++ &amp;gt; General: opencv\build\include Linker &amp;gt; General: opencv\build\x64\vc15\lib Linker &amp;gt; Input: For openCV_4.5.1: opencv_world451d.lib OR opencv_world451.lib (d for debug) For opencv_3.4.13: opencv_world3413d.lib Add D:\tuyenld\dev\opencv_3.4.13\build\x64\vc15\bin (remember to correct your path) to PATH environment Tăng cường chất lượng hình ảnh Phương pháp xử lý trên điểm ảnh Biến đổi tuyến tính từng đoạn Biến đổi Logarithm Biến đổi âm bản Biến đổi tuyến tính từng đoạn xử lý độ tương phản - giãn độ tương phản xử lý những ảnh có độ tương phản thấp cắt lớp cường độ sáng tách nhiễu và lấy ngưỡng ảnh cắt lớp bit Biến đổi âm bản Biến đổi dải động Histogram equalization (HE) Đây chỉ là một phương pháp, có thể cho kết quả không phải flat toàn spectrum Nếu histogram một bài toán thay đổi liên tục thì phải dùng HE (tự động). Các trường hợp khác thì có thể fixed histogram và không cần dùng đến HE00 Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski) https://github.com/oreillymedia/Learning-OpenCV-3_examples Code Online distanceTransform Ref1 takes binary images as inputs. the gray level intensities of the points inside the foreground regions are changed to distance their respective distances from the closest 0 value (boundary) Type Ref1 Ref2 A Mapping of Type to Numbers in OpenCV   C1 C2 C3 C4 Type Bits C++ type Range CV_8U 0 8 16 24 Unsigned 8bits uchar 0~255 CV_8S 1 9 17 25 Signed 8bits char -128~127 CV_16U 2 10 18 26 Unsigned 16bits ushort 0~65.535 CV_16S 3 11 19 27 Signed 16bits short -32.768~32.767 CV_32S 4 12 20 28 Signed 32bits int -2.147.483.648~2.147.483.647 CV_32F 5 13 21 29 Float 32bits float 0~1.0 CV_64F 6 14 22 30 Double 64bits double   #define CV_8U 0 #define CV_8S 1 #define CV_16U 2 #define CV_16S 3 #define CV_32S 4 #define CV_32F 5 #define CV_64F 6 #define CV_8UC1 CV_MAKETYPE(CV_8U,1) #define CV_8UC2 CV_MAKETYPE(CV_8U,2) #define CV_8UC3 CV_MAKETYPE(CV_8U,3) #define CV_8UC4 CV_MAKETYPE(CV_8U,4) #define CV_8UC(n) CV_MAKETYPE(CV_8U,(n)) #define CV_CN_SHIFT 3 #define CV_DEPTH_MAX (1 &amp;lt;&amp;lt; CV_CN_SHIFT) #define CV_MAT_DEPTH_MASK (CV_DEPTH_MAX - 1) #define CV_MAT_DEPTH(flags) ((flags) &amp;amp; CV_MAT_DEPTH_MASK) #define CV_MAKETYPE(depth,cn) (CV_MAT_DEPTH(depth) + (((cn)-1) &amp;lt;&amp;lt; CV_CN_SHIFT)) // For example: #define CV_8UC4 CV_MAKETYPE(CV_8U,4) // has type: 0+((4-1) &amp;lt;&amp;lt; 3) == 24 1 is the default number of channels (CV_8U = CV_8UC1 = 0) CV_32F defines the depth of each element of the matrix CV_32FC1 defines both the depth of each element and the number of channels. Scalar Template class for a 4-element vector derived from Vec. Being derived from Vec&amp;lt;Tp, 4&amp;gt; , Scalar can be used just as typical 4-element vectors. The type Scalar is widely used in OpenCV to pass pixel values. cv::Scalar myWhite(255, 255, 500); cout &amp;lt;&amp;lt; &quot;Scala0: &quot; &amp;lt;&amp;lt; myWhite[0] &amp;lt;&amp;lt; &quot;; Scala1: &quot; &amp;lt;&amp;lt; myWhite[1] &amp;lt;&amp;lt; &quot;; Scala2: &quot; &amp;lt;&amp;lt; myWhite[2] &amp;lt;&amp;lt; endl; // Scala0: 255; Scala1: 255; Scala2: 500 Differences of using “const cv::Mat &amp;amp;”, “cv::Mat &amp;amp;”, “cv::Mat” or “const cv::Mat” as function parameters? https://stackoverflow.com/a/23486280 OpenCV handles all the memory automatically. First of all, std::vector, Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the Mat::clone method that creates a full copy of the matrix data. Linear vs non-linear filter Ref In cases where the input data contains a large amount of noise but the magnitude is low, a linear low-pass filter may suffice. Conversely, if an image contains a low amount of noise but with relatively high magnitude, then a median filter may be more appropriate. In either case, the filter process changes the overall frequency content of the image. But what is the Fourier Transform? A visual introduction https://youtu.be/spUNpyF58BY Fourier Series &amp;gt; Periodic function of a continuous variable Fourier Transform &amp;gt; Not periodic function CLAHE Contrast Limited Adaptative Histogram Equalization (CLAHE) clahe.c Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV p482/579 Division of the image into 8x8 contextual regions usually gives good results; this implies 64 contextual regions of size 64x64 when AHE is performed on a 512x512 image ?? To avoid visibility of region boundaries, a bilinear interpolation scheme is used (see Fig.2) Laplacian/Laplacian of Gaussian https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm https://hcimage.com/help/Content/Quantitation/Measurements/Processing%20and%20Analysis/Enhance/Enhance%20Operations.htm https://softwarebydefault.com/2013/05/11/image-edge-detection/ The Two-Dimensional Discrete Fourier Transform 2-Dimensional Discrete-Space Fourier Transform edge preserving filter in image processing opencv Wavelet http://www.nsl.hcmus.edu.vn/greenstone/collect/tiensifu/index/assoc/HASH01f6.dir/2.pdf Denoising: wavelet thresholding Ứng dụng phép biến đổi wavelet trong xử lý ảnh PTIT Mean vs Median filter The “mean” is the “average” you’re used to, where you add up all the numbers and then divide by the number of numbers. The “median” is the “middle” value in the list of numbers. Median filter: thích hợp cho ảnh grayscale, không dùng cho binary image Point2f, sub-pixel coordinate origin References: Sub-pixel coordinate origin Absent documentation for sub-pixel coordinate system Conclusion According to results above it seems that cv2.remap uses coordinate system with pixel centers aligned to their integer indexes. top-left pixel center coordinate is (0,0) top left pixel spans from (-0.5,-0.5) to (+0.5,+0.5) whole image spans from (-0.5,-0.5) to (W-0.5, H-0.5) Understanding and evaluating template matching methods alkasm’s anwser TM_SQDIFF_NORMED, TM_CCORR_NORMED, TM_CCOEFF_NORMED TM_SQDIFF, TM_CCORR, TM_CCOEFF TM_CCOEFF_NORMED TM_CCORR_NORMED TM_SQDIFF_NORMED [-1, 1] (mean shifted) [0, 1] [0, 1] Understanding Moments function in opencv Michael Burdinov’s answer Definition of moments in image processing is borrowed from physics. Assume that each pixel in image has weight that is equal to its intensity. Then the point you defined is centroid (a.k.a. center of mass) of image. Assume that I(x,y) is the intensity of pixel (x,y) in image. Then m(i,j) is the sum for all possible x and y of: I(x,y) * (x^i) * (y^j). And here you can read a wiki article about all kinds of image moments (raw moments, central moments, scale/rotation invariant moments and so on). It is pretty good one and I recommend reading it. Adapting this to scalar (greyscale) image with pixel intensities I(x,y), raw image moments Mij are calculated by: ${\displaystyle M_{ij}=\sum {x}\sum _{y}x^{i}y^{j}I(x,y)\,!}M=\sum _{x}\sum _{y}x^{i}y^{j}I(x,y)\,!$ Centroid: ${\displaystyle \,\ {\bar {y}}}=\left{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}{\displaystyle \,\ {\bar {y}}}=\left{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}$ Clone all Fiji source code # https://forum.image.sc/t/getting-the-source-code-for-fiji-without-using-maven/31964/6 sudo apt install maven sudo apt install libxml2-utils git clone git://github.com/fiji/fiji cd fiji/bin wget https://github.com/scijava/scijava-scripts/raw/master/melting-pot.sh bin/melt.sh -s findContours() Reference: mexopencv group__imgproc__shape Remember: In OpenCV, object to be found should be white and background should be black. void cv::findContours ( InputOutputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset = Point() ) // Note: absolute value of an area is used because // area may be positive or negative - in accordance with the // contour orientation double i = std::fabs(cv::contourArea(cv::Mat(contour1))); Contour Approximation Method CHAIN_APPROX_NONE vs CHAIN_APPROX_SIMPLE Contours Hierarchy Contour 0,1,2 are the same hierachy level child(2) = 2a; parent(2a) = 2</summary></entry><entry><title type="html">Bilateral Filter</title><link href="https://deeplearningera.com/bilateral-filter/" rel="alternate" type="text/html" title="Bilateral Filter" /><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://deeplearningera.com/bilateral-filter</id><content type="html" xml:base="https://deeplearningera.com/bilateral-filter/">&lt;h2 id=&quot;nội-dung-cơ-bản-của-thuật-toán&quot;&gt;Nội dung cơ bản của thuật toán&lt;/h2&gt;

&lt;p&gt;Sử dụng hàm Gaussian cho color domain (độ sáng của ảnh) và space domain (vị trí điểm ảnh)
&lt;img src=&quot;/images/bilateral-filter.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Như vậy thuật toán đảm bảo được 2 yếu tố:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Làm mờ ảnh (lọc nhiễu)&lt;/li&gt;
  &lt;li&gt;Bảo toàn edge trong ảnh&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://people.csail.mit.edu/sparis/bf_course/slides/03_definition_bf.pdf&quot;&gt;A Gentle Introduction
to Bilateral Filtering
and its Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="computer-vision" /><summary type="html">Nội dung cơ bản của thuật toán Sử dụng hàm Gaussian cho color domain (độ sáng của ảnh) và space domain (vị trí điểm ảnh) Như vậy thuật toán đảm bảo được 2 yếu tố: Làm mờ ảnh (lọc nhiễu) Bảo toàn edge trong ảnh References A Gentle Introduction to Bilateral Filtering and its Applications</summary></entry><entry><title type="html">Thuật toán Watershed ứng dụng trong xử lý ảnh</title><link href="https://deeplearningera.com/water-shed/" rel="alternate" type="text/html" title="Thuật toán Watershed ứng dụng trong xử lý ảnh" /><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://deeplearningera.com/watershed</id><content type="html" xml:base="https://deeplearningera.com/water-shed/">&lt;h2 id=&quot;các-khái-niệm&quot;&gt;Các khái niệm&lt;/h2&gt;
&lt;p&gt;Mỗi một điểm trên ảnh được chia làm 3 loại sau:
&lt;img src=&quot;/images/khai-niem-co-ban.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;regional minimum: điểm đáy của hình nón&lt;/li&gt;
  &lt;li&gt;catchment basin: vùng từ điểm đáy hình nón đến &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watershed line&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;watershed lines: điểm phân cách giữa các &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thuật toán sẽ đi xác định 3 loại điểm này.&lt;/p&gt;

&lt;h2 id=&quot;các-bước-thực-hiện&quot;&gt;Các bước thực hiện&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Xác định &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regional minimum&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Bắt đầu từ các &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regional minimum&lt;/code&gt;, đổ nước dần dần vào &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Khi nước dâng lên ở &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;, đến một mức nào đó các vùng &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt; này bắt đầu chồng lấn lên nhau. Đây chình là &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watershed lines&lt;/code&gt; cần xác định&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cecas.clemson.edu/~stb/ece847/internal/lectures/lecture04-segmentation.ppt&quot;&gt;cecas.clemson.edu ece847 lecture04-segmentation.ppt&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.math.tau.ac.il/~turkel/notes/watershed_Segmentation.ppt&quot;&gt;tau.ac.il turkel watershed_Segmentation.ppt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="computer-vision" /><summary type="html">Các khái niệm Mỗi một điểm trên ảnh được chia làm 3 loại sau: regional minimum: điểm đáy của hình nón catchment basin: vùng từ điểm đáy hình nón đến watershed line watershed lines: điểm phân cách giữa các catchment basin Thuật toán sẽ đi xác định 3 loại điểm này. Các bước thực hiện Xác định regional minimum Bắt đầu từ các regional minimum, đổ nước dần dần vào catchment basin Khi nước dâng lên ở catchment basin, đến một mức nào đó các vùng catchment basin này bắt đầu chồng lấn lên nhau. Đây chình là watershed lines cần xác định Reference cecas.clemson.edu ece847 lecture04-segmentation.ppt tau.ac.il turkel watershed_Segmentation.ppt</summary></entry><entry><title type="html">How to use masilotti theme</title><link href="https://deeplearningera.com/xctest-name-readability/" rel="alternate" type="text/html" title="How to use masilotti theme" /><published>2021-01-28T00:00:00+00:00</published><updated>2021-01-28T00:00:00+00:00</updated><id>https://deeplearningera.com/xctest-name-readability</id><content type="html" xml:base="https://deeplearningera.com/xctest-name-readability/">&lt;h2 id=&quot;notification-box&quot;&gt;Notification box&lt;/h2&gt;

&lt;div class=&quot;tldr flex rounded-md bg-blue-300 bg-opacity-25 px-4 my-12&quot;&gt;
  &lt;div class=&quot;flex items-center&quot;&gt;
    &lt;div class=&quot;-ml-2 mr-2 my-6 transform rotate-90 tracking-tighter font-semibold text-blue-400&quot;&gt;CODE&lt;/div&gt;
    &lt;p class=&quot;lg:text-lg leading-5 text-blue-800&quot;&gt;This is TLDR notification&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://v1.tailwindcss.com/components/alerts&quot;&gt;See more&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Titled&lt;/p&gt;

&lt;div role=&quot;alert&quot;&gt;
  &lt;div class=&quot;bg-red-500 text-white font-bold rounded-t px-4 py-2&quot;&gt;
    Danger
  &lt;/div&gt;
  &lt;div class=&quot;border border-t-0 border-red-400 rounded-b bg-red-100 px-4 py-3 text-red-700&quot;&gt;
    &lt;p&gt;Something not ideal might be happening.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p class=&quot;text rounded-lg bg-blue-200 bg-opacity-25 text-blue-700 px-8 py-4 my-4&quot;&gt;
  You can now wait for elements in UI Testing with a single line.
&lt;/p&gt;

&lt;p&gt;Notification with images&lt;/p&gt;
&lt;p class=&quot;text rounded-lg bg-blue-200 bg-opacity-25 text-blue-700 px-8 pt-4 pb-8 my-4&quot;&gt;
  Starting with Xcode 12, test failures automatically appear at the calling line!

  &lt;img src=&quot;/images/helper-failure-xcode-12.png&quot; class=&quot;w-full rounded-lg mt-8 mb-0 lg:mb-0&quot; /&gt;
&lt;/p&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;Image scrollable&lt;/p&gt;
&lt;div class=&quot;h-64 overflow-y-scroll&quot;&gt;
  &lt;img src=&quot;/images/xwing.app.png&quot; alt=&quot;Screenshot of https://xwing.app&quot; class=&quot;align-top my-0 lg:my-0&quot; /&gt;
&lt;/div&gt;
&lt;div class=&quot;block text-center mt-4&quot;&gt;Screenshot of the landing page, &lt;a href=&quot;https://xwing.app&quot;&gt;https://xwing.app&lt;/a&gt;.&lt;/div&gt;

&lt;p&gt;Images with text caption&lt;/p&gt;

&lt;div class=&quot;max-w-sm mx-auto&quot;&gt;
  &lt;img src=&quot;/images/two-unit-tests-zero-integration-tests.png&quot; alt=&quot;Two unit tests, zero integration tests&quot; class=&quot;rounded-lg shadow-lg mb-0 lg:mb-0&quot; /&gt;
  &lt;p class=&quot;text-center text-sm text-gray-500&quot;&gt;Two unit tests, zero integration tests&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Items with timelines&lt;/p&gt;

&lt;div class=&quot;relative&quot;&gt;
  &lt;div class=&quot;border-r-4 border-primary-600 absolute h-full&quot; style=&quot;top: 4px; margin-left: 5.15rem;&quot;&gt;&lt;/div&gt;
  &lt;ul class=&quot;timeline list-none m-0 p-0&quot;&gt;
    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 18&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;First notes in notebook&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 19&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Start coding&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 21&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch MVP&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 24&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch landing page&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Sep 9&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch customizations&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Sep 19&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;First paying customer!&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

  &lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;To use this, you have to add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gist&lt;/code&gt; to YAML Front Matter
for example&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;layout: post
gist: https://gist.github.com/tuyenld/79ada5f9e0ffdec990aad2db0becbadd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;flex rounded-md bg-blue-400 bg-opacity-25 px-4 my-12&quot;&gt;
  &lt;div class=&quot;flex-1 items-baseline md:flex md:justify-between&quot;&gt;
    &lt;p class=&quot;text-sm leading-5 text-blue-700&quot;&gt;
      The code from this post is available on GitHub as a single gist.
    &lt;/p&gt;

    &lt;p class=&quot;text-sm leading-5 md:mt-0 md:ml-6&quot;&gt;
      &lt;a href=&quot;https://gist.github.com/tuyenld/79ada5f9e0ffdec990aad2db0becbadd&quot; class=&quot;whitespace-no-wrap font-medium text-blue-700 hover:text-blue-600&quot;&gt;
        View the code &amp;rarr;
      &lt;/a&gt;
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here is an advertisement :)&lt;/p&gt;

&lt;div class=&quot;md:flex md:items-center md:justify-between&quot;&gt;
  &lt;h2 class=&quot;text-2xl sm:text-3xl leading-9 sm:leading-10 font-extrabold tracking-tight text-gray-900&quot;&gt;
    Want to level up your testing?
    &lt;br /&gt;
    &lt;span class=&quot;text-xl sm:text-2xl text-primary-600&quot;&gt;I would love to pair program with you!&lt;/span&gt;
  &lt;/h2&gt;

  &lt;div class=&quot;flex lg:flex-shrink-0&quot;&gt;
    &lt;div class=&quot;inline-flex rounded-md shadow&quot;&gt;
      &lt;a href=&quot;mailto:tuyenld.work@gmail.com&quot; class=&quot;no-underline inline-flex items-center justify-center px-4 md:px-5 py-2 md:py-3 border border-transparent text-base leading-6 font-medium rounded-md text-white bg-primary-600 hover:bg-primary-500 focus:outline-none focus:shadow-outline transition duration-150 ease-in-out&quot;&gt;
        &lt;span class=&quot;mr-4&quot;&gt;&lt;svg class=&quot;h-6 w-6&quot; fill=&quot;currentColor&quot; viewBox=&quot;0 0 20 20&quot;&gt;
  &lt;path d=&quot;M15.989,19.129c0-2.246-2.187-3.389-4.317-4.307c-2.123-0.914-2.801-1.684-2.801-3.334 c0-0.989,0.648-0.667,0.932-2.481c0.12-0.752,0.692-0.012,0.802-1.729c0-0.684-0.313-0.854-0.313-0.854s0.159-1.013,0.221-1.793 c0.064-0.817-0.398-2.56-2.301-3.095C7.88,1.195,7.655,0.654,8.679,0.112c-2.24-0.104-2.761,1.068-3.954,1.93 c-1.015,0.756-1.289,1.953-1.24,2.59c0.065,0.78,0.223,1.793,0.223,1.793s-0.314,0.17-0.314,0.854 c0.11,1.718,0.684,0.977,0.803,1.729C4.481,10.822,5.13,10.5,5.13,11.489c0,1.65-0.212,2.21-2.336,3.124 C0.663,15.53,0,17,0.011,19.129C0.014,19.766,0,20,0,20h16C16,20,15.989,19.766,15.989,19.129z M18.528,13.365 c-1.135-0.457-1.605-1.002-1.605-2.066c0-0.641,0.418-0.432,0.602-1.603c0.077-0.484,0.447-0.008,0.518-1.115 c0-0.441-0.202-0.551-0.202-0.551s0.103-0.656,0.143-1.159c0.05-0.627-0.364-2.247-2.268-2.247c-1.903,0-2.318,1.62-2.269,2.247 c0.042,0.502,0.144,1.159,0.144,1.159s-0.202,0.109-0.202,0.551c0.071,1.107,0.441,0.631,0.518,1.115 c0.184,1.172,0.602,0.963,0.602,1.603c0,1.064-0.438,1.562-1.809,2.152c-0.069,0.029-0.12,0.068-0.183,0.102 c1.64,0.712,4.226,1.941,4.838,4.447H20c0,0,0-1.906,0-2.318C20,14.682,19.727,13.848,18.528,13.365z&quot; /&gt;
&lt;/svg&gt;
&lt;/span&gt;
        Pair with Tuyen
      &lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here is some series&lt;/p&gt;

&lt;div class=&quot;bg-gray-100 text-gray-800 rounded-lg shadow-lg px-8 py-1 lg:py-1&quot;&gt;
  &lt;p&gt;This is part 1 in a 4-part series on &lt;strong&gt;&lt;/strong&gt;.&lt;/p&gt;

  &lt;ol&gt;
    
    
      
        
        &lt;li&gt;
          
            How to use masilotti theme
          
        &lt;/li&gt;
      
    
      
        
        &lt;li&gt;
          
            &lt;a href=&quot;/bilateral-filter/&quot;&gt;Bilateral Filter&lt;/a&gt;
          
        &lt;/li&gt;
      
    
      
        
        &lt;li&gt;
          
            &lt;a href=&quot;/water-shed/&quot;&gt;Thuật toán Watershed ứng dụng trong xử lý ảnh&lt;/a&gt;
          
        &lt;/li&gt;
      
    
      
        
        &lt;li&gt;
          
            &lt;a href=&quot;/opencv-getting-started/&quot;&gt;OpenCV C++ getting started&lt;/a&gt;
          
        &lt;/li&gt;
      
    
  &lt;/ol&gt;
&lt;/div&gt;

&lt;h2 id=&quot;icons&quot;&gt;Icons&lt;/h2&gt;

&lt;p&gt;🤠
🙏&lt;/p&gt;

&lt;h2 id=&quot;slide&quot;&gt;Slide&lt;/h2&gt;

&lt;p&gt;Feel free to follow along with the slides.&lt;/p&gt;

&lt;div class=&quot;embed-responsive aspect-ratio-16/9&quot;&gt;
  &lt;iframe class=&quot;embed-responsive-item&quot; src=&quot;https://docs.google.com/presentation/d/e/2PACX-1vRynAGN6pexj9XgECGEDU_tp8iENwB6ZrM22q5c9njXULmfnMT6-CPFrAl29Yma6CM4Cfp_BHWiD5lr/embed?start=false&amp;amp;loop=false&amp;amp;delayms=5000&quot; frameborder=&quot;0&quot; width=&quot;960&quot; height=&quot;425&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot; style=&quot;overflow: hidden;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="web" /><summary type="html">Notification box</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.mugshotbot.com/m?theme=two_up&amp;mode=light&amp;color=green&amp;pattern=diagonal_lines&amp;image=d33ff6b7&amp;url=https://masilotti.com/xctest-name-readability/" /><media:content medium="image" url="https://www.mugshotbot.com/m?theme=two_up&amp;mode=light&amp;color=green&amp;pattern=diagonal_lines&amp;image=d33ff6b7&amp;url=https://masilotti.com/xctest-name-readability/" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>