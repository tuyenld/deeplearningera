<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://deeplearningera.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://deeplearningera.com/" rel="alternate" type="text/html" /><updated>2021-03-26T01:31:04+00:00</updated><id>https://deeplearningera.com/feed.xml</id><title type="html">deeplearningera.com</title><subtitle>A blog from Dinh-Tuyen Le, an independent developer who's passionate about clean, testable code.</subtitle><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><entry><title type="html">OpenCV C++ getting started</title><link href="https://deeplearningera.com/opencv-getting-started/" rel="alternate" type="text/html" title="OpenCV C++ getting started" /><published>2021-03-25T00:00:00+00:00</published><updated>2021-03-25T00:00:00+00:00</updated><id>https://deeplearningera.com/opencv</id><content type="html" xml:base="https://deeplearningera.com/opencv-getting-started/">&lt;h1 id=&quot;install&quot;&gt;Install&lt;/h1&gt;

&lt;h2 id=&quot;download&quot;&gt;Download&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Microsoft Visual C++ 2019 &lt;a href=&quot;https://download.visualstudio.microsoft.com/download/pr/3a7354bc-d2e4-430f-92d0-9abd031b5ee5/d9fc228ea71a98adc7bc5f5d8e8800684c647e955601ed721fcb29f74ace7536/vs_Community.exe&quot;&gt;Community&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nchc.dl.sourceforge.net/project/opencvlibrary/4.5.1/opencv-4.5.1-vc14_vc15.exe&quot;&gt;opencv_4.5.1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nchc.dl.sourceforge.net/project/opencvlibrary/3.4.13/opencv-3.4.13-vc14_vc15.exe&quot;&gt;opencv_3.4.13&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;configure&quot;&gt;Configure&lt;/h2&gt;
&lt;p&gt;https://acodary.wordpress.com/2018/07/24/opencv-cai-dat-opencv-visual-c-tren-windows/&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Project &amp;gt; Property
    &lt;ul&gt;
      &lt;li&gt;Platform: x64&lt;/li&gt;
      &lt;li&gt;Configuration Properties
        &lt;ul&gt;
          &lt;li&gt;C/C++ &amp;gt; General: opencv\build\include&lt;/li&gt;
          &lt;li&gt;Linker &amp;gt; General: opencv\build\x64\vc15\lib&lt;/li&gt;
          &lt;li&gt;Linker &amp;gt; Input:
            &lt;ul&gt;
              &lt;li&gt;For openCV_4.5.1: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world451d.lib&lt;/code&gt; OR &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world451.lib&lt;/code&gt; (d for debug)&lt;/li&gt;
              &lt;li&gt;For opencv_3.4.13: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv_world3413d.lib&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;D:\tuyenld\dev\opencv_3.4.13\build\x64\vc15\bin&lt;/code&gt; (remember to correct your path) to PATH environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tƒÉng-c∆∞·ªùng-ch·∫•t-l∆∞·ª£ng-h√¨nh-·∫£nh&quot;&gt;TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng h√¨nh ·∫£nh&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Ph∆∞∆°ng ph√°p x·ª≠ l√Ω tr√™n ƒëi·ªÉm ·∫£nh
    &lt;ul&gt;
      &lt;li&gt;Bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh t·ª´ng ƒëo·∫°n&lt;/li&gt;
      &lt;li&gt;Bi·∫øn ƒë·ªïi Logarithm&lt;/li&gt;
      &lt;li&gt;Bi·∫øn ƒë·ªïi √¢m b·∫£n&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh t·ª´ng ƒëo·∫°n
    &lt;ul&gt;
      &lt;li&gt;x·ª≠ l√Ω ƒë·ªô t∆∞∆°ng ph·∫£n - gi√£n ƒë·ªô t∆∞∆°ng ph·∫£n
        &lt;ul&gt;
          &lt;li&gt;x·ª≠ l√Ω nh·ªØng ·∫£nh c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n th·∫•p&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;c·∫Øt l·ªõp c∆∞·ªùng ƒë·ªô s√°ng&lt;/li&gt;
      &lt;li&gt;t√°ch nhi·ªÖu v√† l·∫•y ng∆∞·ª°ng ·∫£nh&lt;/li&gt;
      &lt;li&gt;c·∫Øt l·ªõp bit&lt;/li&gt;
      &lt;li&gt;Bi·∫øn ƒë·ªïi √¢m b·∫£n&lt;/li&gt;
      &lt;li&gt;Bi·∫øn ƒë·ªïi d·∫£i ƒë·ªông&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learning-opencv-3-computer-vision-in-c-with-the-opencv-library-adrian-kaehler-and-gary-bradski&quot;&gt;Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski)&lt;/h2&gt;

&lt;p&gt;https://github.com/oreillymedia/Learning-OpenCV-3_examples&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.opencv.org/3.4.13&quot;&gt;Online&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;distancetransform&quot;&gt;distanceTransform&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm&quot;&gt;Ref1&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;takes &lt;strong&gt;binary images&lt;/strong&gt; as inputs.&lt;/li&gt;
  &lt;li&gt;the &lt;strong&gt;gray level intensities&lt;/strong&gt; of the points inside the foreground regions are changed to distance their respective distances from the closest 0 value (boundary)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;type&quot;&gt;Type&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ninghang.blogspot.com/2012/11/list-of-mat-type-in-opencv.html&quot;&gt;Ref1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/8377091/what-are-the-differences-between-cv-8u-and-cv-32f-and-what-should-i-worry-about/8377146&quot;&gt;Ref2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A Mapping of Type to Numbers in OpenCV&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;¬†&lt;/th&gt;
      &lt;th&gt;C1&lt;/th&gt;
      &lt;th&gt;C2&lt;/th&gt;
      &lt;th&gt;C3&lt;/th&gt;
      &lt;th&gt;C4&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Bits&lt;/th&gt;
      &lt;th&gt;C++ type&lt;/th&gt;
      &lt;th&gt;Range&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_8U&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;Unsigned&lt;/td&gt;
      &lt;td&gt;8bits&lt;/td&gt;
      &lt;td&gt;uchar&lt;/td&gt;
      &lt;td&gt;0~255&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_8S&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;8bits&lt;/td&gt;
      &lt;td&gt;char&lt;/td&gt;
      &lt;td&gt;-128~127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_16U&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;Unsigned&lt;/td&gt;
      &lt;td&gt;16bits&lt;/td&gt;
      &lt;td&gt;ushort&lt;/td&gt;
      &lt;td&gt;0~65.535&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_16S&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;16bits&lt;/td&gt;
      &lt;td&gt;short&lt;/td&gt;
      &lt;td&gt;-32.768~32.767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_32S&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;Signed&lt;/td&gt;
      &lt;td&gt;32bits&lt;/td&gt;
      &lt;td&gt;int&lt;/td&gt;
      &lt;td&gt;-2.147.483.648~2.147.483.647&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_32F&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;Float&lt;/td&gt;
      &lt;td&gt;32bits&lt;/td&gt;
      &lt;td&gt;float&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0~1.0&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CV_64F&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;Double&lt;/td&gt;
      &lt;td&gt;64bits&lt;/td&gt;
      &lt;td&gt;double&lt;/td&gt;
      &lt;td&gt;¬†&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;del&gt;1 is the default number of channels&lt;/del&gt;&lt;/li&gt;
  &lt;li&gt;CV_32F defines the depth of each element of the matrix
CV_32FC1 defines both the depth of each element and the number of channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scalar&quot;&gt;Scalar&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Template class for a 4-element vector derived from Vec.
Being derived from Vec&amp;lt;Tp, 4&amp;gt; , 
Scalar can be used just as typical 4-element vectors. 
The type Scalar is widely used in OpenCV to pass pixel values.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scalar&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Scala0: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;; Scala1: &quot;&lt;/span&gt; 
     &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;; Scala2: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myWhite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Scala0: 255; Scala1: 255; Scala2: 500&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;differences-of-using-const-cvmat--cvmat--cvmat-or-const-cvmat-as-function-parameters&quot;&gt;Differences of using ‚Äúconst cv::Mat &amp;amp;‚Äù, ‚Äúcv::Mat &amp;amp;‚Äù, ‚Äúcv::Mat‚Äù or ‚Äúconst cv::Mat‚Äù as function parameters?&lt;/h1&gt;

&lt;p&gt;https://stackoverflow.com/a/23486280&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;OpenCV handles all the memory &lt;a href=&quot;https://docs.opencv.org/2.4/modules/core/doc/intro.html#automatic-memory-management&quot;&gt;automatically&lt;/a&gt;.
First of all, std::vector, Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the Mat::clone method that creates a full copy of the matrix data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;linear-vs-non-linear-filter&quot;&gt;Linear vs non-linear filter&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://www.embeddedcomputing.com/technology/analog-and-power/comparing-linear-versus-nonlinear-filters-in-image-processing&quot;&gt;Ref&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;In cases where the input data contains a large amount of noise but the magnitude is low, a linear low-pass filter may suffice.&lt;/li&gt;
    &lt;li&gt;Conversely, if an image contains a low amount of noise but with relatively high magnitude, then a median filter may be more appropriate. In either case, the filter process changes the overall frequency content of the image.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;but-what-is-the-fourier-transform-a-visual-introduction&quot;&gt;But what is the Fourier Transform? A visual introduction&lt;/h1&gt;

&lt;p&gt;https://youtu.be/spUNpyF58BY&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fourier Series &amp;gt; Periodic function of a continuous variable&lt;/li&gt;
  &lt;li&gt;Fourier Transform &amp;gt; Not periodic function&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;clahe&quot;&gt;CLAHE&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20120113220509/http://radonc.ucsf.edu/research_group/jpouliot/tutorial/HU/Lesson7.htm&quot;&gt;Contrast Limited Adaptative Histogram Equalization (CLAHE)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/erich666/GraphicsGems/blob/master/gemsiv/clahe.c&quot;&gt;clahe.c&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cas.xav.free.fr/Graphics%20Gems%204%20-%20Paul%20S.%20Heckbert.pdf&quot;&gt;Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV p482/579&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Division of the image into 8x8 contextual regions usually gives good results; this implies 64 contextual regions of size 64x64 when AHE is performed on a 512x512 image&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;??&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To avoid visibility of region boundaries, a &lt;a href=&quot;https://theailearner.com/2018/12/29/image-processing-bilinear-interpolation/&quot;&gt;bilinear interpolation&lt;/a&gt; scheme is used (see Fig.2)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;laplacianlaplacian-of-gaussian&quot;&gt;Laplacian/Laplacian of Gaussian&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm&lt;/li&gt;
  &lt;li&gt;https://hcimage.com/help/Content/Quantitation/Measurements/Processing%20and%20Analysis/Enhance/Enhance%20Operations.htm&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://softwarebydefault.com/2013/05/11/image-edge-detection/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/Iz6C1ny-F2Q&quot;&gt;The Two-Dimensional Discrete Fourier Transform&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/YYGltoYEmKo&quot;&gt;2-Dimensional Discrete-Space Fourier Transform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;edge preserving filter in image processing opencv&lt;/p&gt;

&lt;h1 id=&quot;wavelet&quot;&gt;Wavelet&lt;/h1&gt;

&lt;p&gt;http://www.nsl.hcmus.edu.vn/greenstone/collect/tiensifu/index/assoc/HASH01f6.dir/2.pdf
&lt;a href=&quot;https://blancosilva.wordpress.com/teaching/mathematical-imaging/denoising-wavelet-thresholding/&quot;&gt;Denoising: wavelet thresholding&lt;/a&gt;
&lt;a href=&quot;https://vdocuments.mx/download/ung-dung-phep-bien-doi-wavelet-trong-xu-ly-anh&quot;&gt;·ª®ng d·ª•ng ph√©p bi·∫øn ƒë·ªïi wavelet trong x·ª≠ l√Ω ·∫£nh PTIT&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;mean-vs-median&quot;&gt;Mean vs Median&lt;/h1&gt;
&lt;p&gt;The ‚Äúmean‚Äù is the ‚Äúaverage‚Äù you‚Äôre used to, where you add up all the numbers and then divide by the number of numbers. 
The ‚Äúmedian‚Äù is the ‚Äúmiddle‚Äù value in the list of numbers.&lt;/p&gt;

&lt;h1 id=&quot;point2f-sub-pixel-coordinate-origin&quot;&gt;Point2f, sub-pixel coordinate origin&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;References:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://answers.opencv.org/question/87923/sub-pixel-coordinate-origin/&quot;&gt;Sub-pixel coordinate origin&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/opencv/opencv/issues/10130&quot;&gt;Absent documentation for sub-pixel coordinate system&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;According to results above it seems that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cv2.remap&lt;/code&gt; uses coordinate system with pixel centers aligned to their integer indexes.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;top-left pixel center&lt;/code&gt; coordinate is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0,0)&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;top left pixel spans from (-0.5,-0.5) to (+0.5,+0.5)&lt;/li&gt;
      &lt;li&gt;whole image spans from (-0.5,-0.5) to (W-0.5, H-0.5)
&lt;img src=&quot;images/point2f-coordinate.png&quot; alt=&quot;Point2f coordinate&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="opencv" /><summary type="html">Install Download Microsoft Visual C++ 2019 Community opencv_4.5.1 opencv_3.4.13 Configure https://acodary.wordpress.com/2018/07/24/opencv-cai-dat-opencv-visual-c-tren-windows/ Project &amp;gt; Property Platform: x64 Configuration Properties C/C++ &amp;gt; General: opencv\build\include Linker &amp;gt; General: opencv\build\x64\vc15\lib Linker &amp;gt; Input: For openCV_4.5.1: opencv_world451d.lib OR opencv_world451.lib (d for debug) For opencv_3.4.13: opencv_world3413d.lib Add D:\tuyenld\dev\opencv_3.4.13\build\x64\vc15\bin (remember to correct your path) to PATH environment TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng h√¨nh ·∫£nh Ph∆∞∆°ng ph√°p x·ª≠ l√Ω tr√™n ƒëi·ªÉm ·∫£nh Bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh t·ª´ng ƒëo·∫°n Bi·∫øn ƒë·ªïi Logarithm Bi·∫øn ƒë·ªïi √¢m b·∫£n Bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh t·ª´ng ƒëo·∫°n x·ª≠ l√Ω ƒë·ªô t∆∞∆°ng ph·∫£n - gi√£n ƒë·ªô t∆∞∆°ng ph·∫£n x·ª≠ l√Ω nh·ªØng ·∫£nh c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n th·∫•p c·∫Øt l·ªõp c∆∞·ªùng ƒë·ªô s√°ng t√°ch nhi·ªÖu v√† l·∫•y ng∆∞·ª°ng ·∫£nh c·∫Øt l·ªõp bit Bi·∫øn ƒë·ªïi √¢m b·∫£n Bi·∫øn ƒë·ªïi d·∫£i ƒë·ªông Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski) https://github.com/oreillymedia/Learning-OpenCV-3_examples Code Online distanceTransform Ref1 takes binary images as inputs. the gray level intensities of the points inside the foreground regions are changed to distance their respective distances from the closest 0 value (boundary) Type Ref1 Ref2 A Mapping of Type to Numbers in OpenCV ¬† C1 C2 C3 C4 Type Bits C++ type Range CV_8U 0 8 16 24 Unsigned 8bits uchar 0~255 CV_8S 1 9 17 25 Signed 8bits char -128~127 CV_16U 2 10 18 26 Unsigned 16bits ushort 0~65.535 CV_16S 3 11 19 27 Signed 16bits short -32.768~32.767 CV_32S 4 12 20 28 Signed 32bits int -2.147.483.648~2.147.483.647 CV_32F 5 13 21 29 Float 32bits float 0~1.0 CV_64F 6 14 22 30 Double 64bits double ¬† 1 is the default number of channels CV_32F defines the depth of each element of the matrix CV_32FC1 defines both the depth of each element and the number of channels. Scalar Template class for a 4-element vector derived from Vec. Being derived from Vec&amp;lt;Tp, 4&amp;gt; , Scalar can be used just as typical 4-element vectors. The type Scalar is widely used in OpenCV to pass pixel values. cv::Scalar myWhite(255, 255, 500); cout &amp;lt;&amp;lt; &quot;Scala0: &quot; &amp;lt;&amp;lt; myWhite[0] &amp;lt;&amp;lt; &quot;; Scala1: &quot; &amp;lt;&amp;lt; myWhite[1] &amp;lt;&amp;lt; &quot;; Scala2: &quot; &amp;lt;&amp;lt; myWhite[2] &amp;lt;&amp;lt; endl; // Scala0: 255; Scala1: 255; Scala2: 500 Differences of using ‚Äúconst cv::Mat &amp;amp;‚Äù, ‚Äúcv::Mat &amp;amp;‚Äù, ‚Äúcv::Mat‚Äù or ‚Äúconst cv::Mat‚Äù as function parameters? https://stackoverflow.com/a/23486280 OpenCV handles all the memory automatically. First of all, std::vector, Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the Mat::clone method that creates a full copy of the matrix data. Linear vs non-linear filter Ref In cases where the input data contains a large amount of noise but the magnitude is low, a linear low-pass filter may suffice. Conversely, if an image contains a low amount of noise but with relatively high magnitude, then a median filter may be more appropriate. In either case, the filter process changes the overall frequency content of the image. But what is the Fourier Transform? A visual introduction https://youtu.be/spUNpyF58BY Fourier Series &amp;gt; Periodic function of a continuous variable Fourier Transform &amp;gt; Not periodic function CLAHE Contrast Limited Adaptative Histogram Equalization (CLAHE) clahe.c Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV p482/579 Division of the image into 8x8 contextual regions usually gives good results; this implies 64 contextual regions of size 64x64 when AHE is performed on a 512x512 image ?? To avoid visibility of region boundaries, a bilinear interpolation scheme is used (see Fig.2) Laplacian/Laplacian of Gaussian https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm https://hcimage.com/help/Content/Quantitation/Measurements/Processing%20and%20Analysis/Enhance/Enhance%20Operations.htm https://softwarebydefault.com/2013/05/11/image-edge-detection/ The Two-Dimensional Discrete Fourier Transform 2-Dimensional Discrete-Space Fourier Transform edge preserving filter in image processing opencv Wavelet http://www.nsl.hcmus.edu.vn/greenstone/collect/tiensifu/index/assoc/HASH01f6.dir/2.pdf Denoising: wavelet thresholding ·ª®ng d·ª•ng ph√©p bi·∫øn ƒë·ªïi wavelet trong x·ª≠ l√Ω ·∫£nh PTIT Mean vs Median The ‚Äúmean‚Äù is the ‚Äúaverage‚Äù you‚Äôre used to, where you add up all the numbers and then divide by the number of numbers. The ‚Äúmedian‚Äù is the ‚Äúmiddle‚Äù value in the list of numbers. Point2f, sub-pixel coordinate origin References: Sub-pixel coordinate origin Absent documentation for sub-pixel coordinate system Conclusion According to results above it seems that cv2.remap uses coordinate system with pixel centers aligned to their integer indexes. top-left pixel center coordinate is (0,0) top left pixel spans from (-0.5,-0.5) to (+0.5,+0.5) whole image spans from (-0.5,-0.5) to (W-0.5, H-0.5)</summary></entry><entry><title type="html">Thu·∫≠t to√°n Watershed ·ª©ng d·ª•ng trong x·ª≠ l√Ω ·∫£nh</title><link href="https://deeplearningera.com/water-shed/" rel="alternate" type="text/html" title="Thu·∫≠t to√°n Watershed ·ª©ng d·ª•ng trong x·ª≠ l√Ω ·∫£nh" /><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://deeplearningera.com/watershed</id><content type="html" xml:base="https://deeplearningera.com/water-shed/">&lt;h1 id=&quot;c√°c-kh√°i-ni·ªám&quot;&gt;C√°c kh√°i ni·ªám&lt;/h1&gt;
&lt;p&gt;M·ªói m·ªôt ƒëi·ªÉm tr√™n ·∫£nh ƒë∆∞·ª£c chia l√†m 3 lo·∫°i sau:
&lt;img src=&quot;/images/khai-niem-co-ban.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;regional minimum: ƒëi·ªÉm ƒë√°y c·ªßa h√¨nh n√≥n&lt;/li&gt;
  &lt;li&gt;catchment basin: v√πng t·ª´ ƒëi·ªÉm ƒë√°y h√¨nh n√≥n ƒë·∫øn &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watershed line&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;watershed lines: ƒëi·ªÉm ph√¢n c√°ch gi·ªØa c√°c &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thu·∫≠t to√°n s·∫Ω ƒëi x√°c ƒë·ªãnh 3 lo·∫°i ƒëi·ªÉm n√†y.&lt;/p&gt;

&lt;h1 id=&quot;c√°c-b∆∞·ªõc&quot;&gt;C√°c b∆∞·ªõc&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;X√°c ƒë·ªãnh &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regional minimum&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;B·∫Øt ƒë·∫ßu t·ª´ c√°c &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regional minimum&lt;/code&gt;, ƒë·ªï n∆∞·ªõc d·∫ßn d·∫ßn v√†o &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Khi n∆∞·ªõc d√¢ng l√™n ·ªü &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt;, ƒë·∫øn m·ªôt m·ª©c n√†o ƒë√≥ c√°c v√πng &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catchment basin&lt;/code&gt; n√†y b·∫Øt ƒë·∫ßu ch·ªìng l·∫•n l√™n nhau. ƒê√¢y ch√¨nh l√† &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watershed lines&lt;/code&gt; c·∫ßn x√°c ƒë·ªãnh&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cecas.clemson.edu/~stb/ece847/internal/lectures/lecture04-segmentation.ppt&quot;&gt;cecas.clemson.edu ece847 lecture04-segmentation.ppt&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.math.tau.ac.il/~turkel/notes/watershed_Segmentation.ppt&quot;&gt;tau.ac.il turkel watershed_Segmentation.ppt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="computer-vision" /><summary type="html">C√°c kh√°i ni·ªám M·ªói m·ªôt ƒëi·ªÉm tr√™n ·∫£nh ƒë∆∞·ª£c chia l√†m 3 lo·∫°i sau: regional minimum: ƒëi·ªÉm ƒë√°y c·ªßa h√¨nh n√≥n catchment basin: v√πng t·ª´ ƒëi·ªÉm ƒë√°y h√¨nh n√≥n ƒë·∫øn watershed line watershed lines: ƒëi·ªÉm ph√¢n c√°ch gi·ªØa c√°c catchment basin Thu·∫≠t to√°n s·∫Ω ƒëi x√°c ƒë·ªãnh 3 lo·∫°i ƒëi·ªÉm n√†y. C√°c b∆∞·ªõc X√°c ƒë·ªãnh regional minimum B·∫Øt ƒë·∫ßu t·ª´ c√°c regional minimum, ƒë·ªï n∆∞·ªõc d·∫ßn d·∫ßn v√†o catchment basin Khi n∆∞·ªõc d√¢ng l√™n ·ªü catchment basin, ƒë·∫øn m·ªôt m·ª©c n√†o ƒë√≥ c√°c v√πng catchment basin n√†y b·∫Øt ƒë·∫ßu ch·ªìng l·∫•n l√™n nhau. ƒê√¢y ch√¨nh l√† watershed lines c·∫ßn x√°c ƒë·ªãnh Reference cecas.clemson.edu ece847 lecture04-segmentation.ppt tau.ac.il turkel watershed_Segmentation.ppt</summary></entry><entry><title type="html">How to use masilotti theme</title><link href="https://deeplearningera.com/xctest-name-readability/" rel="alternate" type="text/html" title="How to use masilotti theme" /><published>2021-01-28T00:00:00+00:00</published><updated>2021-01-28T00:00:00+00:00</updated><id>https://deeplearningera.com/xctest-name-readability</id><content type="html" xml:base="https://deeplearningera.com/xctest-name-readability/">&lt;h2 id=&quot;notification-box&quot;&gt;Notification box&lt;/h2&gt;

&lt;div class=&quot;tldr flex rounded-md bg-blue-300 bg-opacity-25 px-4 my-12&quot;&gt;
  &lt;div class=&quot;flex items-center&quot;&gt;
    &lt;div class=&quot;-ml-2 mr-2 my-6 transform rotate-90 tracking-tighter font-semibold text-blue-400&quot;&gt;CODE&lt;/div&gt;
    &lt;p class=&quot;lg:text-lg leading-5 text-blue-800&quot;&gt;This is TLDR notification&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://v1.tailwindcss.com/components/alerts&quot;&gt;See more&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Titled&lt;/p&gt;

&lt;div role=&quot;alert&quot;&gt;
  &lt;div class=&quot;bg-red-500 text-white font-bold rounded-t px-4 py-2&quot;&gt;
    Danger
  &lt;/div&gt;
  &lt;div class=&quot;border border-t-0 border-red-400 rounded-b bg-red-100 px-4 py-3 text-red-700&quot;&gt;
    &lt;p&gt;Something not ideal might be happening.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p class=&quot;text rounded-lg bg-blue-200 bg-opacity-25 text-blue-700 px-8 py-4 my-4&quot;&gt;
  You can now wait for elements in UI Testing with a single line.
&lt;/p&gt;

&lt;p&gt;Notification with images&lt;/p&gt;
&lt;p class=&quot;text rounded-lg bg-blue-200 bg-opacity-25 text-blue-700 px-8 pt-4 pb-8 my-4&quot;&gt;
  Starting with Xcode 12, test failures automatically appear at the calling line!

  &lt;img src=&quot;/images/helper-failure-xcode-12.png&quot; class=&quot;w-full rounded-lg mt-8 mb-0 lg:mb-0&quot; /&gt;
&lt;/p&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;Image scrollable&lt;/p&gt;
&lt;div class=&quot;h-64 overflow-y-scroll&quot;&gt;
  &lt;img src=&quot;/images/xwing.app.png&quot; alt=&quot;Screenshot of https://xwing.app&quot; class=&quot;align-top my-0 lg:my-0&quot; /&gt;
&lt;/div&gt;
&lt;div class=&quot;block text-center mt-4&quot;&gt;Screenshot of the landing page, &lt;a href=&quot;https://xwing.app&quot;&gt;https://xwing.app&lt;/a&gt;.&lt;/div&gt;

&lt;p&gt;Images with text caption&lt;/p&gt;

&lt;div class=&quot;max-w-sm mx-auto&quot;&gt;
  &lt;img src=&quot;/images/two-unit-tests-zero-integration-tests.png&quot; alt=&quot;Two unit tests, zero integration tests&quot; class=&quot;rounded-lg shadow-lg mb-0 lg:mb-0&quot; /&gt;
  &lt;p class=&quot;text-center text-sm text-gray-500&quot;&gt;Two unit tests, zero integration tests&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Items with timelines&lt;/p&gt;

&lt;div class=&quot;relative&quot;&gt;
  &lt;div class=&quot;border-r-4 border-primary-600 absolute h-full&quot; style=&quot;top: 4px; margin-left: 5.15rem;&quot;&gt;&lt;/div&gt;
  &lt;ul class=&quot;timeline list-none m-0 p-0&quot;&gt;
    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 18&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;First notes in notebook&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 19&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Start coding&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 21&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch MVP&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Aug 24&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch landing page&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Sep 9&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;Launch customizations&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

    &lt;li class=&quot;mb-4 pt-0 lg:pt-0&quot;&gt;
  &lt;div class=&quot;flex items-center pb-3&quot;&gt;
    &lt;div class=&quot;w-12 text-right font-bold text-xs tracking-wide uppercase text-gray-600 mr-5&quot;&gt;Sep 19&lt;/div&gt;
    &lt;div class=&quot;bg-white border-4 border-primary-600 rounded-full h-6 w-6&quot;&gt;&lt;/div&gt;
    &lt;div class=&quot;font-medium text-gray-800 ml-5&quot;&gt;First paying customer!&lt;/div&gt;
  &lt;/div&gt;
&lt;/li&gt;

  &lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;To use this, you have to add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gist&lt;/code&gt; to YAML Front Matter
for example&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;layout: post
gist: https://gist.github.com/tuyenld/79ada5f9e0ffdec990aad2db0becbadd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;flex rounded-md bg-blue-400 bg-opacity-25 px-4 my-12&quot;&gt;
  &lt;div class=&quot;flex-1 items-baseline md:flex md:justify-between&quot;&gt;
    &lt;p class=&quot;text-sm leading-5 text-blue-700&quot;&gt;
      The code from this post is available on GitHub as a single gist.
    &lt;/p&gt;

    &lt;p class=&quot;text-sm leading-5 md:mt-0 md:ml-6&quot;&gt;
      &lt;a href=&quot;https://gist.github.com/tuyenld/79ada5f9e0ffdec990aad2db0becbadd&quot; class=&quot;whitespace-no-wrap font-medium text-blue-700 hover:text-blue-600&quot;&gt;
        View the code &amp;rarr;
      &lt;/a&gt;
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here is an advertisement :)&lt;/p&gt;

&lt;div class=&quot;md:flex md:items-center md:justify-between&quot;&gt;
  &lt;h2 class=&quot;text-2xl sm:text-3xl leading-9 sm:leading-10 font-extrabold tracking-tight text-gray-900&quot;&gt;
    Want to level up your testing?
    &lt;br /&gt;
    &lt;span class=&quot;text-xl sm:text-2xl text-primary-600&quot;&gt;I would love to pair program with you!&lt;/span&gt;
  &lt;/h2&gt;

  &lt;div class=&quot;flex lg:flex-shrink-0&quot;&gt;
    &lt;div class=&quot;inline-flex rounded-md shadow&quot;&gt;
      &lt;a href=&quot;mailto:tuyenld.work@gmail.com&quot; class=&quot;no-underline inline-flex items-center justify-center px-4 md:px-5 py-2 md:py-3 border border-transparent text-base leading-6 font-medium rounded-md text-white bg-primary-600 hover:bg-primary-500 focus:outline-none focus:shadow-outline transition duration-150 ease-in-out&quot;&gt;
        &lt;span class=&quot;mr-4&quot;&gt;&lt;svg class=&quot;h-6 w-6&quot; fill=&quot;currentColor&quot; viewBox=&quot;0 0 20 20&quot;&gt;
  &lt;path d=&quot;M15.989,19.129c0-2.246-2.187-3.389-4.317-4.307c-2.123-0.914-2.801-1.684-2.801-3.334 c0-0.989,0.648-0.667,0.932-2.481c0.12-0.752,0.692-0.012,0.802-1.729c0-0.684-0.313-0.854-0.313-0.854s0.159-1.013,0.221-1.793 c0.064-0.817-0.398-2.56-2.301-3.095C7.88,1.195,7.655,0.654,8.679,0.112c-2.24-0.104-2.761,1.068-3.954,1.93 c-1.015,0.756-1.289,1.953-1.24,2.59c0.065,0.78,0.223,1.793,0.223,1.793s-0.314,0.17-0.314,0.854 c0.11,1.718,0.684,0.977,0.803,1.729C4.481,10.822,5.13,10.5,5.13,11.489c0,1.65-0.212,2.21-2.336,3.124 C0.663,15.53,0,17,0.011,19.129C0.014,19.766,0,20,0,20h16C16,20,15.989,19.766,15.989,19.129z M18.528,13.365 c-1.135-0.457-1.605-1.002-1.605-2.066c0-0.641,0.418-0.432,0.602-1.603c0.077-0.484,0.447-0.008,0.518-1.115 c0-0.441-0.202-0.551-0.202-0.551s0.103-0.656,0.143-1.159c0.05-0.627-0.364-2.247-2.268-2.247c-1.903,0-2.318,1.62-2.269,2.247 c0.042,0.502,0.144,1.159,0.144,1.159s-0.202,0.109-0.202,0.551c0.071,1.107,0.441,0.631,0.518,1.115 c0.184,1.172,0.602,0.963,0.602,1.603c0,1.064-0.438,1.562-1.809,2.152c-0.069,0.029-0.12,0.068-0.183,0.102 c1.64,0.712,4.226,1.941,4.838,4.447H20c0,0,0-1.906,0-2.318C20,14.682,19.727,13.848,18.528,13.365z&quot; /&gt;
&lt;/svg&gt;
&lt;/span&gt;
        Pair with Tuyen
      &lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here is some series&lt;/p&gt;

&lt;div class=&quot;bg-gray-100 text-gray-800 rounded-lg shadow-lg px-8 py-1 lg:py-1&quot;&gt;
  &lt;p&gt;This is part 1 in a 3-part series on &lt;strong&gt;&lt;/strong&gt;.&lt;/p&gt;

  &lt;ol&gt;
    
    
      
        
        &lt;li&gt;
          
            How to use masilotti theme
          
        &lt;/li&gt;
      
    
      
        
        &lt;li&gt;
          
            &lt;a href=&quot;/water-shed/&quot;&gt;Thu·∫≠t to√°n Watershed ·ª©ng d·ª•ng trong x·ª≠ l√Ω ·∫£nh&lt;/a&gt;
          
        &lt;/li&gt;
      
    
      
        
        &lt;li&gt;
          
            &lt;a href=&quot;/opencv-getting-started/&quot;&gt;OpenCV C++ getting started&lt;/a&gt;
          
        &lt;/li&gt;
      
    
  &lt;/ol&gt;
&lt;/div&gt;

&lt;h2 id=&quot;icons&quot;&gt;Icons&lt;/h2&gt;

&lt;p&gt;ü§†
üôè&lt;/p&gt;

&lt;h2 id=&quot;slide&quot;&gt;Slide&lt;/h2&gt;

&lt;p&gt;Feel free to follow along with the slides.&lt;/p&gt;

&lt;div class=&quot;embed-responsive aspect-ratio-16/9&quot;&gt;
  &lt;iframe class=&quot;embed-responsive-item&quot; src=&quot;https://docs.google.com/presentation/d/e/2PACX-1vRynAGN6pexj9XgECGEDU_tp8iENwB6ZrM22q5c9njXULmfnMT6-CPFrAl29Yma6CM4Cfp_BHWiD5lr/embed?start=false&amp;amp;loop=false&amp;amp;delayms=5000&quot; frameborder=&quot;0&quot; width=&quot;960&quot; height=&quot;425&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot; style=&quot;overflow: hidden;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;</content><author><name>Dinh-Tuyen Le</name><email>tuyenld.work@gmail.com</email></author><category term="web" /><summary type="html">Notification box</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.mugshotbot.com/m?theme=two_up&amp;mode=light&amp;color=green&amp;pattern=diagonal_lines&amp;image=d33ff6b7&amp;url=https://masilotti.com/xctest-name-readability/" /><media:content medium="image" url="https://www.mugshotbot.com/m?theme=two_up&amp;mode=light&amp;color=green&amp;pattern=diagonal_lines&amp;image=d33ff6b7&amp;url=https://masilotti.com/xctest-name-readability/" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>